{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ndyis/CTI-NLP-MODELS/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdIFe09b3IgR"
      },
      "source": [
        "# **Step 1: Install Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tl3sAckuybO5"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets seqeval torch pandas scikit-learn evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!pip install spacy tqdm nltk\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "vY2S7sWIyU6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV2j0guL8mFJ",
        "outputId": "0807d531-0609-4f9a-f8d0-7e47ab7b90b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A_5RuVS35ie"
      },
      "source": [
        "# **Step 2: Parse and Prepare Your Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y-KOsj3R3Evk",
        "outputId": "9818fe16-f13d-49cd-92df-880e368b1d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "Reading JSON data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading JSON data: 500it [00:00, 885.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 500 records from JSON file\n",
            "Processing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting text content: 100%|██████████| 500/500 [00:00<00:00, 119136.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted 500 text samples\n",
            "Sources distribution: {'rss': 360, 'telegram': 100, 'twitter': 40}\n",
            "\n",
            "Sample text content:\n",
            "Watering Hole Attacks Push ScanBox Keylogger\n",
            "\n",
            "Share this article:\n",
            "Researchers uncover a watering hole attack likely carried out by APT TA423, which attempts to plant the ScanBox JavaScript-based reconnaissance tool.\n",
            "A China-based threat actor has ramped up efforts to distribute the ScanBox reconnaissance framework to victims that include domestic Australian organizations and offshore energy firms in the South China Sea. The bait used by the advanced threat group (APT) is targeted messages that s...\n",
            "\n",
            "Processed data saved to /content/drive/MyDrive/Colab Notebooks/cti-news-processed.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# File path\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/cti-news.json\"\n",
        "\n",
        "# Function to read JSON data line by line\n",
        "def read_json_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, desc=\"Reading JSON data\"):\n",
        "            try:\n",
        "                # Each line is a separate JSON object\n",
        "                json_obj = json.loads(line.strip())\n",
        "                data.append(json_obj)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error parsing JSON line: {e}\")\n",
        "    return data\n",
        "\n",
        "# Function to extract text content based on source\n",
        "def extract_text_content(item):\n",
        "    try:\n",
        "        if item['key'] == 'rss':\n",
        "            # For RSS items, combine title and full content\n",
        "            value = item['value']\n",
        "            title = value.get('title', '')\n",
        "            content = value.get('full_content', '')\n",
        "            if content is None:  # Handle null content\n",
        "                content = ''\n",
        "            return f\"{title}\\n\\n{content}\".strip()\n",
        "\n",
        "        elif item['key'] == 'telegram':\n",
        "            # For Telegram items, use the text field\n",
        "            return item['value'].get('text', '').strip()\n",
        "\n",
        "        elif item['key'] == 'twitter':\n",
        "            # For Twitter items, use the text field\n",
        "            return item['value'].get('text', '').strip()\n",
        "\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Read the JSON data\n",
        "print(\"Reading JSON data...\")\n",
        "json_data = read_json_data(file_path)\n",
        "print(f\"Loaded {len(json_data)} records from JSON file\")\n",
        "\n",
        "# Convert to DataFrame and extract text content\n",
        "print(\"Processing data...\")\n",
        "processed_data = []\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Extracting text content\"):\n",
        "    text = extract_text_content(item)\n",
        "    if text:  # Only include non-empty text\n",
        "        processed_data.append({\n",
        "            'id': item.get('offset', len(processed_data)),\n",
        "            'timestamp': item.get('timestamp'),\n",
        "            'source': item['key'],\n",
        "            'text_content': text\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(processed_data)\n",
        "\n",
        "# Remove any remaining empty content\n",
        "df = df[df['text_content'] != '']\n",
        "\n",
        "# Display statistics\n",
        "print(f\"\\nExtracted {len(df)} text samples\")\n",
        "print(f\"Sources distribution: {df['source'].value_counts().to_dict()}\")\n",
        "\n",
        "# Display a sample\n",
        "print(\"\\nSample text content:\")\n",
        "if not df.empty:\n",
        "    print(df['text_content'].iloc[0][:500] + \"...\")  # Show first 500 chars of first item\n",
        "\n",
        "# Save processed data to CSV for easier handling in next steps\n",
        "output_path = \"/content/drive/MyDrive/Colab Notebooks/cti-news-processed.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"\\nProcessed data saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA-TxAGH56wL"
      },
      "source": [
        "# **Step 3: Tokenize and Prepare Data for NER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "30K0IZUC55uJ",
        "outputId": "1cb6a91b-d1f0-4d0c-9557-b3e2eb5b5077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Loaded 500 processed records\n",
            "Loaded tokenizer: Davlan/bert-base-multilingual-cased-ner-hrl\n",
            "Processing texts into sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing texts: 100%|██████████| 500/500 [00:00<00:00, 1010.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 9641 sentences from 500 documents\n",
            "\n",
            "Sample sentences:\n",
            "[rss] Watering Hole Attacks Push ScanBox Keylogger Share this article: Researchers uncover a watering hole...\n",
            "[rss] A China-based threat actor has ramped up efforts to distribute the ScanBox reconnaissance framework ...\n",
            "[rss] The bait used by the advanced threat group (APT) is targeted messages that supposedly link back to A...\n",
            "[rss] The cyber-espionage campaigns are believed to have launched April 2022 through mid-June 2022, accord...\n",
            "[rss] The threat actor, according to researchers, is believed to be the China-based APT TA423, also known ...\n",
            "\n",
            "Tokenizing sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing:   0%|          | 0/9641 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Tokenizing: 100%|██████████| 9641/9641 [00:01<00:00, 6035.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept 9352 tokenized sentences within length limits\n",
            "Saved tokenized sentences to /content/drive/MyDrive/Colab Notebooks/cti-tokenized-sentences.csv\n",
            "\n",
            "Sample tokenized sentence:\n",
            "Sentence: The cyber-espionage campaigns are believed to have launched April 2022 through mid-June 2022, accord...\n",
            "Tokens: ['The', 'c', '##y', '##ber', '-', 'es', '##pion', '##age', 'campaigns', 'are', 'believed', 'to', 'have', 'launched', 'April', '2022', 'through', 'mid', '-', 'June']...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from google.colab import drive\n",
        "\n",
        "# Download NLTK data - fix the punkt_tab issue\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Add this line\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the processed data\n",
        "processed_data_path = \"/content/drive/MyDrive/Colab Notebooks/cti-news-processed.csv\"\n",
        "df = pd.read_csv(processed_data_path)\n",
        "print(f\"Loaded {len(df)} processed records\")\n",
        "\n",
        "# Load tokenizer - using the multilingual model that performed better in previous tests\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "print(f\"Loaded tokenizer: {model_name}\")\n",
        "\n",
        "# Load spaCy for sentence segmentation\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\"])\n",
        "nlp.max_length = 3000000  # Increase max length for large texts\n",
        "\n",
        "# Function to split text into sentences - using a more robust approach\n",
        "def split_into_sentences(text):\n",
        "    try:\n",
        "        # Use NLTK for sentence tokenization\n",
        "        sentences = sent_tokenize(text)\n",
        "        # Filter out very short sentences (likely not useful for NER)\n",
        "        return [s.strip() for s in sentences if len(s.strip()) > 10]\n",
        "    except LookupError:\n",
        "        # Fallback to a simple regex-based approach if NLTK fails\n",
        "        print(\"Using fallback sentence splitter\")\n",
        "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
        "        return [s.strip() for s in sentences if len(s.strip()) > 10]\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove URLs (simplified pattern)\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Process each text into sentences\n",
        "print(\"Processing texts into sentences...\")\n",
        "all_sentences = []\n",
        "sentence_sources = []  # Keep track of which source each sentence came from\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing texts\"):\n",
        "    text = row['text_content']\n",
        "    source = row['source']\n",
        "\n",
        "    # Clean the text\n",
        "    cleaned_text = clean_text(text)\n",
        "\n",
        "    # Split into sentences\n",
        "    sentences = split_into_sentences(cleaned_text)\n",
        "\n",
        "    # Add to our collections\n",
        "    all_sentences.extend(sentences)\n",
        "    sentence_sources.extend([source] * len(sentences))\n",
        "\n",
        "print(f\"Generated {len(all_sentences)} sentences from {len(df)} documents\")\n",
        "\n",
        "# Create a DataFrame with sentences\n",
        "sentences_df = pd.DataFrame({\n",
        "    'sentence': all_sentences,\n",
        "    'source': sentence_sources\n",
        "})\n",
        "\n",
        "# Sample some sentences to verify\n",
        "print(\"\\nSample sentences:\")\n",
        "for i in range(min(5, len(sentences_df))):\n",
        "    print(f\"[{sentences_df.iloc[i]['source']}] {sentences_df.iloc[i]['sentence'][:100]}...\")\n",
        "\n",
        "# Tokenize sentences using the transformer tokenizer\n",
        "print(\"\\nTokenizing sentences...\")\n",
        "tokenized_sentences = []\n",
        "\n",
        "for sentence in tqdm(sentences_df['sentence'], desc=\"Tokenizing\"):\n",
        "    # Tokenize with the transformer tokenizer\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    # Only keep sentences with a reasonable number of tokens\n",
        "    if 5 <= len(tokens) <= 128:\n",
        "        tokenized_sentences.append({\n",
        "            'sentence': sentence,\n",
        "            'tokens': tokens\n",
        "        })\n",
        "\n",
        "print(f\"Kept {len(tokenized_sentences)} tokenized sentences within length limits\")\n",
        "\n",
        "# Save the tokenized sentences for the next step\n",
        "tokenized_df = pd.DataFrame(tokenized_sentences)\n",
        "tokenized_path = \"/content/drive/MyDrive/Colab Notebooks/cti-tokenized-sentences.csv\"\n",
        "tokenized_df.to_csv(tokenized_path, index=False)\n",
        "print(f\"Saved tokenized sentences to {tokenized_path}\")\n",
        "\n",
        "# Display a sample of tokenized sentences\n",
        "print(\"\\nSample tokenized sentence:\")\n",
        "if not tokenized_df.empty:\n",
        "    sample_idx = min(3, len(tokenized_df) - 1)\n",
        "    sample = tokenized_df.iloc[sample_idx]\n",
        "    print(f\"Sentence: {sample['sentence'][:100]}...\")\n",
        "    print(f\"Tokens: {sample['tokens'][:20]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLqvtHenIB5b"
      },
      "source": [
        "# **Step 4: Create Initial NER Annotations**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the tokenized sentences\n",
        "tokenized_path = \"/content/drive/MyDrive/Colab Notebooks/cti-tokenized-sentences.csv\"\n",
        "tokenized_df = pd.read_csv(tokenized_path)\n",
        "print(f\"Loaded {len(tokenized_df)} tokenized sentences\")\n",
        "\n",
        "# Load spaCy for additional NER\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define CTI-specific keywords with expanded lists for better coverage\n",
        "cti_keywords = {\n",
        "    \"THREAT_ACTOR\": [\n",
        "        \"APT\", \"threat actor\", \"hacker group\", \"threat group\", \"cybercriminal\",\n",
        "        \"nation-state actor\", \"Lazarus\", \"Fancy Bear\", \"Cozy Bear\", \"APT29\", \"APT28\",\n",
        "        \"Sandworm\", \"TA423\", \"Red Ladon\", \"Kimsuky\", \"Conti\", \"LockBit\", \"BlackCat\",\n",
        "        \"Nobelium\", \"Mustang Panda\", \"Volt Typhoon\", \"Scattered Spider\", \"Midnight Blizzard\",\n",
        "        \"Cl0p\", \"Lapsus$\", \"REvil\", \"DarkSide\", \"BlackMatter\", \"FIN7\", \"FIN8\"\n",
        "    ],\n",
        "    \"MALWARE\": [\n",
        "        \"malware\", \"ransomware\", \"trojan\", \"virus\", \"worm\", \"backdoor\", \"spyware\",\n",
        "        \"keylogger\", \"rootkit\", \"bootkit\", \"adware\", \"ScanBox\", \"SUNBURST\", \"BLINDINGCAN\",\n",
        "        \"Emotet\", \"TrickBot\", \"Ryuk\", \"WannaCry\", \"NotPetya\", \"BlackEnergy\", \"Stuxnet\",\n",
        "        \"Duqu\", \"Flame\", \"Gauss\", \"ZeuS\", \"SpyEye\", \"Dridex\", \"Locky\", \"CryptoLocker\",\n",
        "        \"BlackEnergy\", \"DarkHotel\", \"Industroyer\", \"BlackEnergy\", \"PlugX\", \"Cobalt Strike\"\n",
        "    ],\n",
        "    \"VULNERABILITY\": [\n",
        "        \"vulnerability\", \"exploit\", \"zero-day\", \"CVE-\", \"security flaw\", \"security bug\",\n",
        "        \"security vulnerability\", \"RCE\", \"code execution\", \"buffer overflow\", \"SQL injection\",\n",
        "        \"cross-site scripting\", \"XSS\", \"CSRF\", \"path traversal\", \"command injection\",\n",
        "        \"privilege escalation\", \"authentication bypass\", \"memory corruption\", \"use-after-free\",\n",
        "        \"integer overflow\", \"race condition\", \"insecure deserialization\", \"SSRF\", \"XXE\"\n",
        "    ],\n",
        "    \"ATTACK_PATTERN\": [\n",
        "        \"phishing\", \"spear-phishing\", \"watering hole\", \"DDoS\", \"brute force\",\n",
        "        \"credential stuffing\", \"social engineering\", \"XSS\", \"SQL injection\",\n",
        "        \"man-in-the-middle\", \"supply chain attack\", \"lateral movement\", \"privilege escalation\",\n",
        "        \"data exfiltration\", \"command and control\", \"C2\", \"living off the land\", \"fileless malware\",\n",
        "        \"password spraying\", \"credential harvesting\", \"business email compromise\", \"BEC\",\n",
        "        \"island hopping\", \"drive-by download\", \"typosquatting\", \"smishing\", \"vishing\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Helper function to convert tensor to native Python type\n",
        "def to_python_type(obj):\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.item()\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, np.float32) or isinstance(obj, np.float64):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.int32) or isinstance(obj, np.int64):\n",
        "        return int(obj)\n",
        "    return obj\n",
        "\n",
        "# Load pre-trained NER model\n",
        "print(\"Loading pre-trained NER model...\")\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded and moved to {device}\")\n",
        "\n",
        "# Create NER pipeline\n",
        "ner_pipeline = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Function to find keyword matches in text\n",
        "def find_keyword_matches(text, entity_type, keywords):\n",
        "    matches = []\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    for keyword in keywords:\n",
        "        keyword_lower = keyword.lower()\n",
        "        start = 0\n",
        "        while True:\n",
        "            pos = text_lower.find(keyword_lower, start)\n",
        "            if pos == -1:\n",
        "                break\n",
        "\n",
        "            # Add entity with proper case from the original text\n",
        "            entity_text = text[pos:pos + len(keyword)]\n",
        "            matches.append({\n",
        "                'entity_type': entity_type,\n",
        "                'text': entity_text,\n",
        "                'start': pos,\n",
        "                'end': pos + len(keyword),\n",
        "                'source': 'keyword'\n",
        "            })\n",
        "\n",
        "            start = pos + 1\n",
        "\n",
        "    return matches\n",
        "\n",
        "# Function to convert spaCy entities to our format\n",
        "def convert_spacy_entities(doc):\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        # Map spaCy entity types to our schema\n",
        "        entity_type = None\n",
        "        if ent.label_ in [\"ORG\", \"ORGANIZATION\"]:\n",
        "            entity_type = \"ORG\"\n",
        "        elif ent.label_ in [\"PERSON\", \"PER\"]:\n",
        "            entity_type = \"PER\"\n",
        "        elif ent.label_ in [\"LOC\", \"GPE\", \"LOCATION\"]:\n",
        "            entity_type = \"LOC\"\n",
        "        elif ent.label_ in [\"MISC\"]:\n",
        "            entity_type = \"MISC\"\n",
        "\n",
        "        if entity_type:\n",
        "            entities.append({\n",
        "                'entity_type': entity_type,\n",
        "                'text': ent.text,\n",
        "                'start': ent.start_char,\n",
        "                'end': ent.end_char,\n",
        "                'source': 'spacy'\n",
        "            })\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Function to convert transformer NER entities to our format\n",
        "def convert_transformer_entities(entities, text):\n",
        "    converted = []\n",
        "    for entity in entities:\n",
        "        # Map transformer entity types to our schema\n",
        "        entity_type = None\n",
        "        if entity['entity_group'] in [\"ORG\", \"ORGANIZATION\", \"I-ORG\", \"B-ORG\"]:\n",
        "            entity_type = \"ORG\"\n",
        "        elif entity['entity_group'] in [\"PER\", \"PERSON\", \"I-PER\", \"B-PER\"]:\n",
        "            entity_type = \"PER\"\n",
        "        elif entity['entity_group'] in [\"LOC\", \"LOCATION\", \"I-LOC\", \"B-LOC\"]:\n",
        "            entity_type = \"LOC\"\n",
        "        elif entity['entity_group'] in [\"MISC\", \"I-MISC\", \"B-MISC\"]:\n",
        "            entity_type = \"MISC\"\n",
        "\n",
        "        if entity_type:\n",
        "            # Convert score to Python float\n",
        "            score = to_python_type(entity.get('score', 0.0))\n",
        "\n",
        "            converted.append({\n",
        "                'entity_type': entity_type,\n",
        "                'text': entity['word'],\n",
        "                'start': entity['start'],\n",
        "                'end': entity['end'],\n",
        "                'source': 'transformer',\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "    return converted\n",
        "\n",
        "# Process each sentence to create annotations\n",
        "print(\"Creating initial NER annotations...\")\n",
        "annotated_sentences = []\n",
        "\n",
        "for idx, row in tqdm(tokenized_df.iterrows(), total=len(tokenized_df), desc=\"Annotating sentences\"):\n",
        "    sentence = row['sentence']\n",
        "    tokens = eval(row['tokens']) if isinstance(row['tokens'], str) else row['tokens']\n",
        "\n",
        "    # Get entities from transformer model\n",
        "    try:\n",
        "        transformer_entities = ner_pipeline(sentence)\n",
        "        transformer_entities = convert_transformer_entities(transformer_entities, sentence)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with transformer NER for sentence {idx}: {e}\")\n",
        "        transformer_entities = []\n",
        "\n",
        "    # Get entities from spaCy\n",
        "    try:\n",
        "        doc = nlp(sentence)\n",
        "        spacy_entities = convert_spacy_entities(doc)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with spaCy NER for sentence {idx}: {e}\")\n",
        "        spacy_entities = []\n",
        "\n",
        "    # Get keyword matches for CTI entities\n",
        "    keyword_entities = []\n",
        "    for entity_type, keywords in cti_keywords.items():\n",
        "        matches = find_keyword_matches(sentence, entity_type, keywords)\n",
        "        keyword_entities.extend(matches)\n",
        "\n",
        "    # Combine all entities\n",
        "    all_entities = transformer_entities + spacy_entities + keyword_entities\n",
        "\n",
        "    # Remove overlapping entities (prefer keyword > transformer > spaCy)\n",
        "    non_overlapping = []\n",
        "    all_entities.sort(key=lambda x: (x['start'], -len(x['text'])))  # Sort by start position and then by length (descending)\n",
        "\n",
        "    for entity in all_entities:\n",
        "        # Check if this entity overlaps with any already selected entity\n",
        "        overlaps = False\n",
        "        for selected in non_overlapping:\n",
        "            if (entity['start'] < selected['end'] and entity['end'] > selected['start']):\n",
        "                # If keyword entity, it takes precedence\n",
        "                if entity['source'] == 'keyword' and selected['source'] != 'keyword':\n",
        "                    non_overlapping.remove(selected)\n",
        "                    non_overlapping.append(entity)\n",
        "                overlaps = True\n",
        "                break\n",
        "\n",
        "        if not overlaps:\n",
        "            non_overlapping.append(entity)\n",
        "\n",
        "    # Sort entities by start position\n",
        "    non_overlapping.sort(key=lambda x: x['start'])\n",
        "\n",
        "    # Add to annotated sentences\n",
        "    annotated_sentences.append({\n",
        "        'sentence': sentence,\n",
        "        'tokens': tokens,\n",
        "        'entities': non_overlapping\n",
        "    })\n",
        "\n",
        "print(f\"Created annotations for {len(annotated_sentences)} sentences\")\n",
        "\n",
        "# Save the annotated sentences\n",
        "annotated_path = \"/content/drive/MyDrive/Colab Notebooks/cti-annotated-sentences.json\"\n",
        "with open(annotated_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(annotated_sentences, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved annotated sentences to {annotated_path}\")\n",
        "\n",
        "# Display a sample of annotated sentences\n",
        "print(\"\\nSample annotated sentence:\")\n",
        "if annotated_sentences:\n",
        "    sample_idx = min(3, len(annotated_sentences) - 1)\n",
        "    sample = annotated_sentences[sample_idx]\n",
        "    print(f\"Sentence: {sample['sentence'][:100]}...\")\n",
        "    print(f\"Entities:\")\n",
        "    for entity in sample['entities']:\n",
        "        print(f\"  - {entity['text']} ({entity['entity_type']}) [{entity['start']}:{entity['end']}] from {entity['source']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b6nma5Nvzn-H",
        "outputId": "5070929f-e533-43e3-8071-dac0909aeb71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Loaded 9352 tokenized sentences\n",
            "Loading pre-trained NER model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and moved to cuda\n",
            "Creating initial NER annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotating sentences: 100%|██████████| 9352/9352 [03:28<00:00, 44.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created annotations for 9352 sentences\n",
            "Saved annotated sentences to /content/drive/MyDrive/Colab Notebooks/cti-annotated-sentences.json\n",
            "\n",
            "Sample annotated sentence:\n",
            "Sentence: The cyber-espionage campaigns are believed to have launched April 2022 through mid-June 2022, accord...\n",
            "Entities:\n",
            "  - Proofpoint’s Threat Research Team (ORG) [112:145] from spacy\n",
            "  - PwC (ORG) [150:153] from transformer\n",
            "  - Threat Intelligence (ORG) [156:175] from transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACpZkAjVKcTo"
      },
      "source": [
        "# **# Step 5: Convert Annotations to Training Format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xB3RDhZ9KgtN",
        "outputId": "1a2d4e13-ba0f-4844-8db0-6c0bcd64b373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded 9352 annotated sentences\n",
            "Converting annotations to token-level training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 9352/9352 [00:01<00:00, 5460.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 9352 token-level training examples\n",
            "Split into 7481 training and 1871 test examples\n",
            "Saved training data to /content/drive/MyDrive/Colab Notebooks/cti-train-data.json\n",
            "Saved test data to /content/drive/MyDrive/Colab Notebooks/cti-test-data.json\n",
            "\n",
            "Sample training example:\n",
            "Sentence: Users of Zymbra Collaboration should install the update as soon as possible....\n",
            "Tokens: ['User', '##s', 'of', 'Z', '##ym', '##bra', 'Coll', '##aboration', 'should', 'instal']...\n",
            "Labels: ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O']...\n",
            "\n",
            "Entity type counts in training data:\n",
            "  - ORG: 18886\n",
            "  - PER: 5096\n",
            "  - VULNERABILITY: 3016\n",
            "  - LOC: 2941\n",
            "  - MALWARE: 2173\n",
            "  - THREAT_ACTOR: 1572\n",
            "  - ATTACK_PATTERN: 1247\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from transformers import AutoTokenizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the annotated sentences\n",
        "annotated_path = \"/content/drive/MyDrive/Colab Notebooks/cti-annotated-sentences.json\"\n",
        "with open(annotated_path, 'r', encoding='utf-8') as f:\n",
        "    annotated_sentences = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(annotated_sentences)} annotated sentences\")\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define our NER label list\n",
        "label_list = [\n",
        "    \"O\",  # Outside (not an entity)\n",
        "    # Person entities\n",
        "    \"B-PER\", \"I-PER\",\n",
        "    # Organization entities\n",
        "    \"B-ORG\", \"I-ORG\",\n",
        "    # Location entities\n",
        "    \"B-LOC\", \"I-LOC\",\n",
        "    # Miscellaneous entities\n",
        "    \"B-MISC\", \"I-MISC\",\n",
        "    # CTI-specific entities\n",
        "    \"B-THREAT_ACTOR\", \"I-THREAT_ACTOR\",\n",
        "    \"B-MALWARE\", \"I-MALWARE\",\n",
        "    \"B-VULNERABILITY\", \"I-VULNERABILITY\",\n",
        "    \"B-ATTACK_PATTERN\", \"I-ATTACK_PATTERN\"\n",
        "]\n",
        "\n",
        "# Create label mappings\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "# Function to convert entity annotations to token-level BIO tags\n",
        "def create_token_labels(sentence, entities, tokenizer):\n",
        "    # Tokenize the sentence\n",
        "    tokenized = tokenizer(sentence, return_offsets_mapping=True, add_special_tokens=False)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(tokenized['input_ids'])\n",
        "    offset_mapping = tokenized['offset_mapping']\n",
        "\n",
        "    # Initialize all labels as \"O\"\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "\n",
        "    # For each entity, find the corresponding tokens and assign BIO tags\n",
        "    for entity in entities:\n",
        "        entity_type = entity['entity_type']\n",
        "        start_char = entity['start']\n",
        "        end_char = entity['end']\n",
        "\n",
        "        # Find tokens that overlap with this entity\n",
        "        entity_tokens = []\n",
        "        for i, (token_start, token_end) in enumerate(offset_mapping):\n",
        "            # Check if this token overlaps with the entity\n",
        "            if token_end > start_char and token_start < end_char:\n",
        "                entity_tokens.append(i)\n",
        "\n",
        "        # Assign BIO tags to the entity tokens\n",
        "        if entity_tokens:\n",
        "            # First token gets B- tag\n",
        "            labels[entity_tokens[0]] = f\"B-{entity_type}\"\n",
        "\n",
        "            # Remaining tokens get I- tag\n",
        "            for i in entity_tokens[1:]:\n",
        "                labels[i] = f\"I-{entity_type}\"\n",
        "\n",
        "    return {\n",
        "        'tokens': tokens,\n",
        "        'labels': labels,\n",
        "        'offset_mapping': offset_mapping\n",
        "    }\n",
        "\n",
        "# Convert all annotated sentences to token-level training data\n",
        "print(\"Converting annotations to token-level training data...\")\n",
        "training_data = []\n",
        "\n",
        "for idx, item in tqdm(enumerate(annotated_sentences), total=len(annotated_sentences), desc=\"Processing\"):\n",
        "    sentence = item['sentence']\n",
        "    entities = item['entities']\n",
        "\n",
        "    # Create token-level labels\n",
        "    token_data = create_token_labels(sentence, entities, tokenizer)\n",
        "\n",
        "    # Add to training data\n",
        "    training_data.append({\n",
        "        'id': idx,\n",
        "        'sentence': sentence,\n",
        "        'tokens': token_data['tokens'],\n",
        "        'labels': token_data['labels'],\n",
        "        'offset_mapping': token_data['offset_mapping']\n",
        "    })\n",
        "\n",
        "print(f\"Created {len(training_data)} token-level training examples\")\n",
        "\n",
        "# Split into train/test sets (80/20 split)\n",
        "random.seed(42)  # For reproducibility\n",
        "random.shuffle(training_data)\n",
        "\n",
        "train_size = int(0.8 * len(training_data))\n",
        "train_data = training_data[:train_size]\n",
        "test_data = training_data[train_size:]\n",
        "\n",
        "print(f\"Split into {len(train_data)} training and {len(test_data)} test examples\")\n",
        "\n",
        "# Save the training and test data\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/cti-train-data.json\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/cti-test-data.json\"\n",
        "\n",
        "with open(train_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(test_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved training data to {train_path}\")\n",
        "print(f\"Saved test data to {test_path}\")\n",
        "\n",
        "# Display a sample of the training data\n",
        "print(\"\\nSample training example:\")\n",
        "if train_data:\n",
        "    sample = train_data[0]\n",
        "    print(f\"Sentence: {sample['sentence'][:100]}...\")\n",
        "    print(f\"Tokens: {sample['tokens'][:10]}...\")\n",
        "    print(f\"Labels: {sample['labels'][:10]}...\")\n",
        "\n",
        "    # Count entity types in the training data\n",
        "    entity_counts = {}\n",
        "    for item in train_data:\n",
        "        for label in item['labels']:\n",
        "            if label != \"O\":\n",
        "                entity_type = label.split('-')[1]\n",
        "                entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n",
        "\n",
        "    print(\"\\nEntity type counts in training data:\")\n",
        "    for entity_type, count in sorted(entity_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"  - {entity_type}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajFtWfsAMHwA"
      },
      "source": [
        "# **Step 6: Create Token-Level Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622,
          "referenced_widgets": [
            "f7f11674172946a9a80a9409ad8992fb",
            "bec59e456aaf4690a6ea36458857c7e4",
            "91cc4c90643f4c73a78fffacf3d068c3",
            "abeaecaea9ca4c169f5653f8fda6eecc",
            "cc35ffda62ad4f15a58757ae7872e463",
            "e0d34ec0fffe48c0a6ffb4af6af8e6d8",
            "1ef72434cb5b4818b5dbd71f732462bb",
            "d0d4e67f1524437789c2c5928ec5e060",
            "0a68ac2a11bd4faebf4efc5f257c6669",
            "ae9d5854007849f19f8c398dc4fc7cab",
            "fb91f7a2cf9f47388390d17534b9c997",
            "7031d33256a74a33a5e68e836ceaae17",
            "33d1cb1196e04714a16ffac5f73ad4a0",
            "79dbbac5f73e4a2b80501bc62c391a5e",
            "344b1862ced24060bca6a19c417838f3",
            "bb592635002b44b883ea89c261c2b1f6",
            "7762bce36bf34b7d96fd91a65ed951f8",
            "fa74667c71b74f66a78c124f7e6048e9",
            "f669a897568746aa9e66541baaf37813",
            "4be0d40bf8d247938022368e7b0c0c85",
            "3b6aa6cdba854079b032b3104dc4bcd8",
            "2e4065d97d1e4819832c716c1fcc38b1",
            "3aabfc5bf6104a519549219f1073cd5d",
            "92da46e2da33474f808c8a9a93a373e5",
            "8c2af394121c4ae7bf6b34d8f000afe2",
            "d72b3b048a36416cb4238cee46739eb4",
            "b89ac64aef8c4bcb8afd8bbc2b931032",
            "52b11d12ab684a3185dbd47f1b4c978a",
            "1a0e4acc79164f759486034e97db1b42",
            "dce7d4e558144c9ab496b12bba795512",
            "250da9d7317b4a69a246e977b58ebc35",
            "b0cd8b0c46aa43589f1e1b0fa0d2ae63",
            "70d45a0453d04608ae6b668daa319328",
            "b73d0fd76f5d4b48981ac926480692c1",
            "090c4b56d55e47258a579f6da90a2807",
            "d266aa98e35943b49a6dda4905ba7915",
            "a70a26869bfb49ffb5bf78a37922beb4",
            "a6225fbda6644477b43a94d58519ab11",
            "cde5a80c2c6940d3968dbf25ef58e049",
            "09c0ec4f44424ac6ab6fd915206762b6",
            "78b16cc8b0024b34b15b4c1f60110420",
            "256c06b8378546caaef83c3aaf5e5012",
            "f408ae9b99f14537b7d90d053c31bc8b",
            "d1a2468ecf6f40c1a83259d282f0cd4f"
          ]
        },
        "collapsed": true,
        "id": "jwaAKi_CMKH7",
        "outputId": "eb2cdbce-037e-4866-86f8-dec818cef518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded 7481 training and 1871 test examples\n",
            "Created Hugging Face datasets with 7481 training and 1871 test examples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7481 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7f11674172946a9a80a9409ad8992fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1871 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7031d33256a74a33a5e68e836ceaae17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized datasets created with 7481 training and 1871 test examples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/7481 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aabfc5bf6104a519549219f1073cd5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1871 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b73d0fd76f5d4b48981ac926480692c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved tokenized datasets to disk\n",
            "\n",
            "Sample from tokenized dataset:\n",
            "Input IDs (first 10): [101, 93974, 108, 108, 187, 10108, 163, 108, 108, 25942]\n",
            "Attention Mask (first 10): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Labels (first 10): [-100, 0, 0, -100, -100, 0, 3, 4, -100, -100]\n",
            "\n",
            "Entity counts in tokenized training data:\n",
            "  - I-ORG: 12785\n",
            "  - B-ORG: 5620\n",
            "  - I-PER: 3280\n",
            "  - I-VULNERABILITY: 1833\n",
            "  - B-LOC: 1752\n",
            "  - B-PER: 1739\n",
            "  - I-MALWARE: 1290\n",
            "  - I-LOC: 1126\n",
            "  - B-VULNERABILITY: 1124\n",
            "  - I-THREAT_ACTOR: 911\n",
            "  - B-MALWARE: 838\n",
            "  - B-THREAT_ACTOR: 655\n",
            "  - I-ATTACK_PATTERN: 617\n",
            "  - B-ATTACK_PATTERN: 607\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the training and test data\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/cti-train-data.json\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/cti-test-data.json\"\n",
        "\n",
        "with open(train_path, 'r', encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(test_path, 'r', encoding='utf-8') as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(train_data)} training and {len(test_data)} test examples\")\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define our NER label list\n",
        "label_list = [\n",
        "    \"O\",  # Outside (not an entity)\n",
        "    # Person entities\n",
        "    \"B-PER\", \"I-PER\",\n",
        "    # Organization entities\n",
        "    \"B-ORG\", \"I-ORG\",\n",
        "    # Location entities\n",
        "    \"B-LOC\", \"I-LOC\",\n",
        "    # Miscellaneous entities\n",
        "    \"B-MISC\", \"I-MISC\",\n",
        "    # CTI-specific entities\n",
        "    \"B-THREAT_ACTOR\", \"I-THREAT_ACTOR\",\n",
        "    \"B-MALWARE\", \"I-MALWARE\",\n",
        "    \"B-VULNERABILITY\", \"I-VULNERABILITY\",\n",
        "    \"B-ATTACK_PATTERN\", \"I-ATTACK_PATTERN\"\n",
        "]\n",
        "\n",
        "# Create label mappings\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "# Function to convert our data to the format expected by the Hugging Face Trainer\n",
        "def convert_to_hf_dataset(data):\n",
        "    # Convert labels to IDs\n",
        "    for item in data:\n",
        "        item['label_ids'] = [label2id[label] for label in item['labels']]\n",
        "\n",
        "    # Create a Hugging Face Dataset\n",
        "    dataset = Dataset.from_dict({\n",
        "        'id': [item['id'] for item in data],\n",
        "        'tokens': [item['tokens'] for item in data],\n",
        "        'labels': [item['label_ids'] for item in data]\n",
        "    })\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Convert our data to Hugging Face datasets\n",
        "train_dataset = convert_to_hf_dataset(train_data)\n",
        "test_dataset = convert_to_hf_dataset(test_data)\n",
        "\n",
        "print(f\"Created Hugging Face datasets with {len(train_dataset)} training and {len(test_dataset)} test examples\")\n",
        "\n",
        "# Function to tokenize and align labels for the model\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to -100\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply tokenization and label alignment\n",
        "train_tokenized = train_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "test_tokenized = test_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names\n",
        ")\n",
        "\n",
        "print(f\"Tokenized datasets created with {len(train_tokenized)} training and {len(test_tokenized)} test examples\")\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Save the prepared datasets\n",
        "train_tokenized.save_to_disk(\"/content/drive/MyDrive/Colab Notebooks/cti-train-tokenized\")\n",
        "test_tokenized.save_to_disk(\"/content/drive/MyDrive/Colab Notebooks/cti-test-tokenized\")\n",
        "\n",
        "print(\"Saved tokenized datasets to disk\")\n",
        "\n",
        "# Display a sample from the tokenized dataset\n",
        "print(\"\\nSample from tokenized dataset:\")\n",
        "sample = train_tokenized[0]\n",
        "print(f\"Input IDs (first 10): {sample['input_ids'][:10]}\")\n",
        "print(f\"Attention Mask (first 10): {sample['attention_mask'][:10]}\")\n",
        "print(f\"Labels (first 10): {sample['labels'][:10]}\")\n",
        "\n",
        "# Count the number of examples with each entity type\n",
        "entity_counts = {label: 0 for label in label_list if label != \"O\"}\n",
        "\n",
        "for example in train_tokenized:\n",
        "    labels = example[\"labels\"]\n",
        "    for label_id in labels:\n",
        "        if label_id >= 0 and label_id < len(label_list) and label_list[label_id] != \"O\":\n",
        "            entity_counts[label_list[label_id]] += 1\n",
        "\n",
        "print(\"\\nEntity counts in tokenized training data:\")\n",
        "for entity, count in sorted(entity_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    if count > 0:\n",
        "        print(f\"  - {entity}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-wGy7fHmxxz"
      },
      "source": [
        "# **Step 7: Fine Tune Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y_g4u4EOmvkM",
        "outputId": "d576965d-cb93-4bd2-8145-cbadc57c251e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "Loaded 7481 training and 1871 test examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Davlan/bert-base-multilingual-cased-ner-hrl and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([17, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and moved to cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-913d91a84ad5>:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2340/2340 08:56, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Pattern Attack</th>\n",
              "      <th>Loc All</th>\n",
              "      <th>Malware All</th>\n",
              "      <th>Org All</th>\n",
              "      <th>Per All</th>\n",
              "      <th>Actor Threat</th>\n",
              "      <th>Vulnerability All</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.154491</td>\n",
              "      <td>0.766690</td>\n",
              "      <td>0.737504</td>\n",
              "      <td>0.751814</td>\n",
              "      <td>0.960129</td>\n",
              "      <td>{'precision': 0.7027027027027027, 'recall': 0.3443708609271523, 'f1': 0.46222222222222226, 'number': 151}</td>\n",
              "      <td>{'precision': 0.9267326732673268, 'recall': 0.9052224371373307, 'f1': 0.9158512720156555, 'number': 517}</td>\n",
              "      <td>{'precision': 0.8071065989847716, 'recall': 0.8784530386740331, 'f1': 0.8412698412698412, 'number': 181}</td>\n",
              "      <td>{'precision': 0.7010752688172043, 'recall': 0.7540478026214341, 'f1': 0.7265973254086181, 'number': 1297}</td>\n",
              "      <td>{'precision': 0.7990762124711316, 'recall': 0.7954022988505747, 'f1': 0.7972350230414745, 'number': 435}</td>\n",
              "      <td>{'precision': 0.7058823529411765, 'recall': 0.5, 'f1': 0.5853658536585366, 'number': 192}</td>\n",
              "      <td>{'precision': 0.7771084337349398, 'recall': 0.5201612903225806, 'f1': 0.6231884057971014, 'number': 248}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.268300</td>\n",
              "      <td>0.122079</td>\n",
              "      <td>0.810901</td>\n",
              "      <td>0.807680</td>\n",
              "      <td>0.809287</td>\n",
              "      <td>0.965769</td>\n",
              "      <td>{'precision': 0.78125, 'recall': 0.8278145695364238, 'f1': 0.8038585209003216, 'number': 151}</td>\n",
              "      <td>{'precision': 0.9456740442655935, 'recall': 0.9090909090909091, 'f1': 0.9270216962524654, 'number': 517}</td>\n",
              "      <td>{'precision': 0.9162011173184358, 'recall': 0.9060773480662984, 'f1': 0.9111111111111111, 'number': 181}</td>\n",
              "      <td>{'precision': 0.7213712618526623, 'recall': 0.7625289128758674, 'f1': 0.7413793103448276, 'number': 1297}</td>\n",
              "      <td>{'precision': 0.851581508515815, 'recall': 0.8045977011494253, 'f1': 0.8274231678486997, 'number': 435}</td>\n",
              "      <td>{'precision': 0.9030303030303031, 'recall': 0.7760416666666666, 'f1': 0.8347338935574229, 'number': 192}</td>\n",
              "      <td>{'precision': 0.8539823008849557, 'recall': 0.7782258064516129, 'f1': 0.8143459915611814, 'number': 248}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.116800</td>\n",
              "      <td>0.119142</td>\n",
              "      <td>0.861808</td>\n",
              "      <td>0.829858</td>\n",
              "      <td>0.845531</td>\n",
              "      <td>0.970187</td>\n",
              "      <td>{'precision': 0.9047619047619048, 'recall': 0.8807947019867549, 'f1': 0.8926174496644295, 'number': 151}</td>\n",
              "      <td>{'precision': 0.9574898785425101, 'recall': 0.9148936170212766, 'f1': 0.9357072205736895, 'number': 517}</td>\n",
              "      <td>{'precision': 0.9597701149425287, 'recall': 0.9226519337016574, 'f1': 0.9408450704225353, 'number': 181}</td>\n",
              "      <td>{'precision': 0.7780320366132724, 'recall': 0.7864302235929067, 'f1': 0.7822085889570551, 'number': 1297}</td>\n",
              "      <td>{'precision': 0.8894736842105263, 'recall': 0.7770114942528735, 'f1': 0.8294478527607362, 'number': 435}</td>\n",
              "      <td>{'precision': 0.9485714285714286, 'recall': 0.8645833333333334, 'f1': 0.904632152588556, 'number': 192}</td>\n",
              "      <td>{'precision': 0.9210526315789473, 'recall': 0.8467741935483871, 'f1': 0.8823529411764707, 'number': 248}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.076300</td>\n",
              "      <td>0.126160</td>\n",
              "      <td>0.852383</td>\n",
              "      <td>0.846739</td>\n",
              "      <td>0.849552</td>\n",
              "      <td>0.971303</td>\n",
              "      <td>{'precision': 0.8874172185430463, 'recall': 0.8874172185430463, 'f1': 0.8874172185430463, 'number': 151}</td>\n",
              "      <td>{'precision': 0.9554655870445344, 'recall': 0.9129593810444874, 'f1': 0.9337289812067259, 'number': 517}</td>\n",
              "      <td>{'precision': 0.9553072625698324, 'recall': 0.9447513812154696, 'f1': 0.9500000000000001, 'number': 181}</td>\n",
              "      <td>{'precision': 0.7846853677028052, 'recall': 0.7979953739398612, 'f1': 0.7912844036697247, 'number': 1297}</td>\n",
              "      <td>{'precision': 0.8090909090909091, 'recall': 0.8183908045977012, 'f1': 0.8137142857142856, 'number': 435}</td>\n",
              "      <td>{'precision': 0.9153439153439153, 'recall': 0.9010416666666666, 'f1': 0.9081364829396326, 'number': 192}</td>\n",
              "      <td>{'precision': 0.9475982532751092, 'recall': 0.875, 'f1': 0.909853249475891, 'number': 248}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.128503</td>\n",
              "      <td>0.847485</td>\n",
              "      <td>0.858987</td>\n",
              "      <td>0.853197</td>\n",
              "      <td>0.971620</td>\n",
              "      <td>{'precision': 0.8823529411764706, 'recall': 0.8940397350993378, 'f1': 0.8881578947368421, 'number': 151}</td>\n",
              "      <td>{'precision': 0.9496981891348089, 'recall': 0.9129593810444874, 'f1': 0.9309664694280079, 'number': 517}</td>\n",
              "      <td>{'precision': 0.9344262295081968, 'recall': 0.9447513812154696, 'f1': 0.9395604395604397, 'number': 181}</td>\n",
              "      <td>{'precision': 0.7750362844702468, 'recall': 0.8234387047031612, 'f1': 0.7985046728971962, 'number': 1297}</td>\n",
              "      <td>{'precision': 0.8198614318706697, 'recall': 0.8160919540229885, 'f1': 0.8179723502304148, 'number': 435}</td>\n",
              "      <td>{'precision': 0.9402173913043478, 'recall': 0.9010416666666666, 'f1': 0.9202127659574467, 'number': 192}</td>\n",
              "      <td>{'precision': 0.9444444444444444, 'recall': 0.8911290322580645, 'f1': 0.9170124481327802, 'number': 248}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating the final model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [117/117 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Results by Epoch:\n",
            "|   Epoch |   Loss |   Precision |   Recall |     F1 |   Accuracy |   Pattern Attack F1 |   Loc F1 |   Malware F1 |   Org F1 |   Per F1 |   Actor Threat F1 |   Vulnerability F1 |\n",
            "|--------:|-------:|------------:|---------:|-------:|-----------:|--------------------:|---------:|-------------:|---------:|---------:|------------------:|-------------------:|\n",
            "|       1 | 0.1545 |      0.7667 |   0.7375 | 0.7518 |     0.9601 |              0.4622 |   0.9159 |       0.8413 |   0.7266 |   0.7972 |            0.5854 |             0.6232 |\n",
            "|       2 | 0.1221 |      0.8109 |   0.8077 | 0.8093 |     0.9658 |              0.8039 |   0.927  |       0.9111 |   0.7414 |   0.8274 |            0.8347 |             0.8143 |\n",
            "|       3 | 0.1191 |      0.8618 |   0.8299 | 0.8455 |     0.9702 |              0.8926 |   0.9357 |       0.9408 |   0.7822 |   0.8294 |            0.9046 |             0.8824 |\n",
            "|       4 | 0.1262 |      0.8524 |   0.8467 | 0.8496 |     0.9713 |              0.8874 |   0.9337 |       0.95   |   0.7913 |   0.8137 |            0.9081 |             0.9099 |\n",
            "|       5 | 0.1285 |      0.8475 |   0.859  | 0.8532 |     0.9716 |              0.8882 |   0.931  |       0.9396 |   0.7985 |   0.818  |            0.9202 |             0.917  |\n",
            "|       5 | 0.1285 |      0.8475 |   0.859  | 0.8532 |     0.9716 |              0.8882 |   0.931  |       0.9396 |   0.7985 |   0.818  |            0.9202 |             0.917  |\n",
            "\n",
            "Final Evaluation Results:\n",
            "eval_loss: 0.1285\n",
            "eval_precision: 0.8475\n",
            "eval_recall: 0.8590\n",
            "eval_f1: 0.8532\n",
            "eval_accuracy: 0.9716\n",
            "eval_PATTERN_ATTACK: 0.8882 (P: 0.8824, R: 0.8940)\n",
            "eval_LOC_all: 0.9310 (P: 0.9497, R: 0.9130)\n",
            "eval_MALWARE_all: 0.9396 (P: 0.9344, R: 0.9448)\n",
            "eval_ORG_all: 0.7985 (P: 0.7750, R: 0.8234)\n",
            "eval_PER_all: 0.8180 (P: 0.8199, R: 0.8161)\n",
            "eval_ACTOR_THREAT: 0.9202 (P: 0.9402, R: 0.9010)\n",
            "eval_VULNERABILITY_all: 0.9170 (P: 0.9444, R: 0.8911)\n",
            "eval_steps_per_second: 16.2680\n",
            "epoch: 5.0000\n",
            "\n",
            "Model saved to /content/drive/MyDrive/Colab Notebooks/NER-model-improved\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
        "from datasets import load_from_disk\n",
        "import evaluate\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Load the tokenized datasets\n",
        "train_dataset = load_from_disk(\"/content/drive/MyDrive/Colab Notebooks/cti-train-tokenized\")\n",
        "test_dataset = load_from_disk(\"/content/drive/MyDrive/Colab Notebooks/cti-test-tokenized\")\n",
        "\n",
        "print(f\"Loaded {len(train_dataset)} training and {len(test_dataset)} test examples\")\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define our NER label list\n",
        "label_list = [\n",
        "    \"O\",  # Outside (not an entity)\n",
        "    # Person entities\n",
        "    \"B-PER\", \"I-PER\",\n",
        "    # Organization entities\n",
        "    \"B-ORG\", \"I-ORG\",\n",
        "    # Location entities\n",
        "    \"B-LOC\", \"I-LOC\",\n",
        "    # Miscellaneous entities\n",
        "    \"B-MISC\", \"I-MISC\",\n",
        "    # CTI-specific entities\n",
        "    \"B-THREAT_ACTOR\", \"I-THREAT_ACTOR\",\n",
        "    \"B-MALWARE\", \"I-MALWARE\",\n",
        "    \"B-VULNERABILITY\", \"I-VULNERABILITY\",\n",
        "    \"B-ATTACK_PATTERN\", \"I-ATTACK_PATTERN\"\n",
        "]\n",
        "\n",
        "# Create label mappings\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "# Load the model - add ignore_mismatched_sizes=True to fix the error\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True  # Add this parameter to fix the error\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded and moved to {device}\")\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Load metric\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    # Extract results for each entity type\n",
        "    entity_results = {}\n",
        "    for key in results.keys():\n",
        "        if key.startswith(\"overall\"):\n",
        "            continue\n",
        "        entity_type = key.split(\"_\")[1] if \"_\" in key else key\n",
        "        metric_type = key.split(\"_\")[0] if \"_\" in key else \"all\"\n",
        "\n",
        "        if entity_type not in entity_results:\n",
        "            entity_results[entity_type] = {}\n",
        "\n",
        "        entity_results[entity_type][metric_type] = results[key]\n",
        "\n",
        "    # Add overall results\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "        **{f\"{entity}_{metric}\": value\n",
        "           for entity, metrics in entity_results.items()\n",
        "           for metric, value in metrics.items()}\n",
        "    }\n",
        "\n",
        "# Define training arguments with more epochs (5 instead of 3)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Colab Notebooks/NER-model-improved\",  # Changed model name\n",
        "    eval_strategy=\"epoch\",  # Fixed deprecated parameter\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,  # Increased from 3 to 5\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if available\n",
        "    report_to=\"none\"  # Disable wandb, tensorboard, etc.\n",
        ")\n",
        "\n",
        "# Create Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=None,  # Removed tokenizer to avoid deprecation warning\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting fine-tuning...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "# Function to format results in a nice table\n",
        "def format_results_table(results_dict):\n",
        "    # Extract epoch results\n",
        "    epochs = []\n",
        "    metrics = []\n",
        "\n",
        "    for log in trainer.state.log_history:\n",
        "        if 'eval_f1' in log:\n",
        "            epoch = log.get('epoch', 0)\n",
        "\n",
        "            # Extract main metrics\n",
        "            main_metrics = {\n",
        "                'Epoch': f\"{epoch:.1f}\",\n",
        "                'Loss': f\"{log.get('eval_loss', 0):.4f}\",\n",
        "                'Precision': f\"{log.get('eval_precision', 0):.4f}\",\n",
        "                'Recall': f\"{log.get('eval_recall', 0):.4f}\",\n",
        "                'F1': f\"{log.get('eval_f1', 0):.4f}\",\n",
        "                'Accuracy': f\"{log.get('eval_accuracy', 0):.4f}\"\n",
        "            }\n",
        "\n",
        "            # Extract entity-specific metrics\n",
        "            entity_metrics = {}\n",
        "            for key, value in log.items():\n",
        "                if key.startswith('eval_') and '_all' in key:\n",
        "                    entity_type = key.split('_')[1].capitalize()\n",
        "                    entity_metrics[f\"{entity_type} F1\"] = f\"{value['f1']:.4f}\"\n",
        "                elif key.startswith('eval_') and any(x in key for x in ['THREAT', 'ATTACK']):\n",
        "                    parts = key.split('_')\n",
        "                    if len(parts) > 1:\n",
        "                        entity_type = ' '.join([p.capitalize() for p in parts[1:]])\n",
        "                        entity_metrics[f\"{entity_type} F1\"] = f\"{value['f1']:.4f}\"\n",
        "\n",
        "            # Combine metrics\n",
        "            combined_metrics = {**main_metrics, **entity_metrics}\n",
        "            metrics.append(combined_metrics)\n",
        "            epochs.append(epoch)\n",
        "\n",
        "    # Create DataFrame and format as table\n",
        "    if metrics:\n",
        "        df = pd.DataFrame(metrics)\n",
        "        table = tabulate(df, headers='keys', tablefmt='pipe', showindex=False)\n",
        "        return table\n",
        "    else:\n",
        "        return \"No evaluation results found\"\n",
        "\n",
        "# Evaluate the final model\n",
        "print(\"\\nEvaluating the final model...\")\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Print formatted results\n",
        "print(\"\\nTraining Results by Epoch:\")\n",
        "results_table = format_results_table(evaluation_results)\n",
        "print(results_table)\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "for key, value in evaluation_results.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"{key}: {value['f1']:.4f} (P: {value['precision']:.4f}, R: {value['recall']:.4f})\")\n",
        "    elif not key.startswith('eval_runtime') and not key.startswith('eval_samples_'):\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Save the fine-tuned model to Google Drive\n",
        "drive_model_path = \"/content/drive/MyDrive/Colab Notebooks/NER-model-improved\"\n",
        "model.save_pretrained(drive_model_path)\n",
        "tokenizer.save_pretrained(drive_model_path)\n",
        "print(f\"\\nModel saved to {drive_model_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOK5RQkab9ksce/r3mRe7bI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7f11674172946a9a80a9409ad8992fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bec59e456aaf4690a6ea36458857c7e4",
              "IPY_MODEL_91cc4c90643f4c73a78fffacf3d068c3",
              "IPY_MODEL_abeaecaea9ca4c169f5653f8fda6eecc"
            ],
            "layout": "IPY_MODEL_cc35ffda62ad4f15a58757ae7872e463"
          }
        },
        "bec59e456aaf4690a6ea36458857c7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d34ec0fffe48c0a6ffb4af6af8e6d8",
            "placeholder": "​",
            "style": "IPY_MODEL_1ef72434cb5b4818b5dbd71f732462bb",
            "value": "Map: 100%"
          }
        },
        "91cc4c90643f4c73a78fffacf3d068c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d4e67f1524437789c2c5928ec5e060",
            "max": 7481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a68ac2a11bd4faebf4efc5f257c6669",
            "value": 7481
          }
        },
        "abeaecaea9ca4c169f5653f8fda6eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae9d5854007849f19f8c398dc4fc7cab",
            "placeholder": "​",
            "style": "IPY_MODEL_fb91f7a2cf9f47388390d17534b9c997",
            "value": " 7481/7481 [00:02&lt;00:00, 2771.52 examples/s]"
          }
        },
        "cc35ffda62ad4f15a58757ae7872e463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d34ec0fffe48c0a6ffb4af6af8e6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef72434cb5b4818b5dbd71f732462bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d4e67f1524437789c2c5928ec5e060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a68ac2a11bd4faebf4efc5f257c6669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae9d5854007849f19f8c398dc4fc7cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb91f7a2cf9f47388390d17534b9c997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7031d33256a74a33a5e68e836ceaae17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d1cb1196e04714a16ffac5f73ad4a0",
              "IPY_MODEL_79dbbac5f73e4a2b80501bc62c391a5e",
              "IPY_MODEL_344b1862ced24060bca6a19c417838f3"
            ],
            "layout": "IPY_MODEL_bb592635002b44b883ea89c261c2b1f6"
          }
        },
        "33d1cb1196e04714a16ffac5f73ad4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7762bce36bf34b7d96fd91a65ed951f8",
            "placeholder": "​",
            "style": "IPY_MODEL_fa74667c71b74f66a78c124f7e6048e9",
            "value": "Map: 100%"
          }
        },
        "79dbbac5f73e4a2b80501bc62c391a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f669a897568746aa9e66541baaf37813",
            "max": 1871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4be0d40bf8d247938022368e7b0c0c85",
            "value": 1871
          }
        },
        "344b1862ced24060bca6a19c417838f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6aa6cdba854079b032b3104dc4bcd8",
            "placeholder": "​",
            "style": "IPY_MODEL_2e4065d97d1e4819832c716c1fcc38b1",
            "value": " 1871/1871 [00:01&lt;00:00, 1706.79 examples/s]"
          }
        },
        "bb592635002b44b883ea89c261c2b1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7762bce36bf34b7d96fd91a65ed951f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa74667c71b74f66a78c124f7e6048e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f669a897568746aa9e66541baaf37813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be0d40bf8d247938022368e7b0c0c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b6aa6cdba854079b032b3104dc4bcd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4065d97d1e4819832c716c1fcc38b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aabfc5bf6104a519549219f1073cd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92da46e2da33474f808c8a9a93a373e5",
              "IPY_MODEL_8c2af394121c4ae7bf6b34d8f000afe2",
              "IPY_MODEL_d72b3b048a36416cb4238cee46739eb4"
            ],
            "layout": "IPY_MODEL_b89ac64aef8c4bcb8afd8bbc2b931032"
          }
        },
        "92da46e2da33474f808c8a9a93a373e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b11d12ab684a3185dbd47f1b4c978a",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0e4acc79164f759486034e97db1b42",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "8c2af394121c4ae7bf6b34d8f000afe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce7d4e558144c9ab496b12bba795512",
            "max": 7481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_250da9d7317b4a69a246e977b58ebc35",
            "value": 7481
          }
        },
        "d72b3b048a36416cb4238cee46739eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cd8b0c46aa43589f1e1b0fa0d2ae63",
            "placeholder": "​",
            "style": "IPY_MODEL_70d45a0453d04608ae6b668daa319328",
            "value": " 7481/7481 [00:00&lt;00:00, 93120.18 examples/s]"
          }
        },
        "b89ac64aef8c4bcb8afd8bbc2b931032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b11d12ab684a3185dbd47f1b4c978a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0e4acc79164f759486034e97db1b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce7d4e558144c9ab496b12bba795512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250da9d7317b4a69a246e977b58ebc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0cd8b0c46aa43589f1e1b0fa0d2ae63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d45a0453d04608ae6b668daa319328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73d0fd76f5d4b48981ac926480692c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_090c4b56d55e47258a579f6da90a2807",
              "IPY_MODEL_d266aa98e35943b49a6dda4905ba7915",
              "IPY_MODEL_a70a26869bfb49ffb5bf78a37922beb4"
            ],
            "layout": "IPY_MODEL_a6225fbda6644477b43a94d58519ab11"
          }
        },
        "090c4b56d55e47258a579f6da90a2807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde5a80c2c6940d3968dbf25ef58e049",
            "placeholder": "​",
            "style": "IPY_MODEL_09c0ec4f44424ac6ab6fd915206762b6",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "d266aa98e35943b49a6dda4905ba7915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b16cc8b0024b34b15b4c1f60110420",
            "max": 1871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_256c06b8378546caaef83c3aaf5e5012",
            "value": 1871
          }
        },
        "a70a26869bfb49ffb5bf78a37922beb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f408ae9b99f14537b7d90d053c31bc8b",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a2468ecf6f40c1a83259d282f0cd4f",
            "value": " 1871/1871 [00:00&lt;00:00, 39870.66 examples/s]"
          }
        },
        "a6225fbda6644477b43a94d58519ab11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde5a80c2c6940d3968dbf25ef58e049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c0ec4f44424ac6ab6fd915206762b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b16cc8b0024b34b15b4c1f60110420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256c06b8378546caaef83c3aaf5e5012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f408ae9b99f14537b7d90d053c31bc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a2468ecf6f40c1a83259d282f0cd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}